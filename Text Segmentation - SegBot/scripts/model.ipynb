{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb44caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as R\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class PointerNetworks(nn.Module):\n",
    "    def __init__(self,voca_size, voc_embeddings,word_dim, hidden_dim,is_bi_encoder_rnn,rnn_type,rnn_layers,\n",
    "                 dropout_prob,use_cuda,finedtuning,isbanor):\n",
    "        super(PointerNetworks,self).__init__()\n",
    "\n",
    "        self.word_dim = word_dim\n",
    "        self.voca_size = voca_size\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.is_bi_encoder_rnn = is_bi_encoder_rnn\n",
    "        self.num_rnn_layers = rnn_layers\n",
    "        self.rnn_type = rnn_type\n",
    "        self.voc_embeddings = voc_embeddings\n",
    "        self.finedtuning = finedtuning\n",
    "\n",
    "        self.nnDropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "        self.isbanor = isbanor\n",
    "\n",
    "\n",
    "        if rnn_type in ['LSTM', 'GRU']:\n",
    "\n",
    "\n",
    "\n",
    "            self.decoder_rnn = getattr(nn, rnn_type)(input_size=word_dim,\n",
    "                                                     hidden_size=2 * hidden_dim if is_bi_encoder_rnn else hidden_dim,\n",
    "                                                     num_layers=rnn_layers,\n",
    "                                                     dropout=dropout_prob,\n",
    "                                                     batch_first=True)\n",
    "\n",
    "            self.encoder_rnn = getattr(nn, rnn_type)(input_size=word_dim,\n",
    "                                       hidden_size=hidden_dim,\n",
    "                                       num_layers=rnn_layers,\n",
    "                                       bidirectional=is_bi_encoder_rnn,\n",
    "                                       dropout=dropout_prob,\n",
    "                                       batch_first=True)\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            print('rnn_type should be LSTM,GRU')\n",
    "\n",
    "\n",
    "\n",
    "        self.nnSELU = nn.SELU()\n",
    "\n",
    "\n",
    "        self.nnEm = nn.Embedding(self.voca_size,self.word_dim)\n",
    "\n",
    "        self.initEmbeddings(self.voc_embeddings)\n",
    "\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if self.is_bi_encoder_rnn:\n",
    "            self.num_encoder_bi = 2\n",
    "        else:\n",
    "            self.num_encoder_bi = 1\n",
    "\n",
    "\n",
    "        self.nnW1 = nn.Linear(self.num_encoder_bi * hidden_dim, self.num_encoder_bi * hidden_dim, bias=False)\n",
    "        self.nnW2 = nn.Linear(self.num_encoder_bi * hidden_dim, self.num_encoder_bi * hidden_dim, bias=False)\n",
    "        self.nnV = nn.Linear(self.num_encoder_bi * hidden_dim, 1, bias=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def initEmbeddings(self,weights):\n",
    "        self.nnEm.weight.data.copy_(torch.from_numpy(weights))\n",
    "        self.nnEm.weight.requires_grad = self.finedtuning\n",
    "\n",
    "\n",
    "    def initHidden(self,hsize,batchsize):\n",
    "\n",
    "\n",
    "        if self.rnn_type == 'LSTM':\n",
    "\n",
    "            h_0 = Variable(torch.zeros(self.num_encoder_bi*self.num_rnn_layers, batchsize, hsize))\n",
    "            c_0 = Variable(torch.zeros(self.num_encoder_bi*self.num_rnn_layers, batchsize, hsize))\n",
    "\n",
    "            if self.use_cuda:\n",
    "                h_0 = h_0.cuda()\n",
    "                c_0 = c_0.cuda()\n",
    "\n",
    "            return (h_0, c_0)\n",
    "        else:\n",
    "\n",
    "            h_0 = Variable(torch.zeros(self.num_encoder_bi*self.num_rnn_layers, batchsize, hsize))\n",
    "\n",
    "            if self.use_cuda:\n",
    "                h_0 = h_0.cuda()\n",
    "\n",
    "\n",
    "            return h_0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _run_rnn_packed(self, cell, x, x_lens, h=None):\n",
    "        x_packed = R.pack_padded_sequence(x, x_lens.data.tolist(),\n",
    "                                          batch_first=True)\n",
    "\n",
    "        if h is not None:\n",
    "            output, h = cell(x_packed, h)\n",
    "        else:\n",
    "            output, h = cell(x_packed)\n",
    "\n",
    "        output, _ = R.pad_packed_sequence(output, batch_first=True)\n",
    "\n",
    "        return output, h\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def pointerEncoder(self,Xin,lens):\n",
    "        self.bn_inputdata = nn.BatchNorm1d(self.word_dim, affine=False, track_running_stats=False)\n",
    "\n",
    "\n",
    "        batch_size,maxL = Xin.size()\n",
    "\n",
    "        X = self.nnEm(Xin)  # N L  C\n",
    "\n",
    "        if self.isbanor and maxL>1:\n",
    "            X= X.permute(0,2,1) # N C L\n",
    "            X = self.bn_inputdata(X)\n",
    "            X = X.permute(0, 2, 1) # N L C\n",
    "\n",
    "        X = self.nnDropout(X)\n",
    "\n",
    "\n",
    "\n",
    "        encoder_lstm_co_h_o = self.initHidden(self.hidden_dim, batch_size)\n",
    "        o, h = self._run_rnn_packed(self.encoder_rnn, X, lens, encoder_lstm_co_h_o)  # batch_first=True\n",
    "        o = o.contiguous()\n",
    "\n",
    "        o = self.nnDropout(o)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return o,h\n",
    "\n",
    "\n",
    "    def pointerLayer(self,en,di):\n",
    "        \"\"\"\n",
    "\n",
    "        :param en:  [L,H]\n",
    "        :param di:  [H,]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        WE = self.nnW1(en)\n",
    "\n",
    "\n",
    "        exdi = di.expand_as(en)\n",
    "\n",
    "        WD = self.nnW2(exdi)\n",
    "\n",
    "        nnV = self.nnV(self.nnSELU(WE+WD))\n",
    "\n",
    "        nnV = nnV.permute(1,0)\n",
    "\n",
    "        nnV = self.nnSELU(nnV)\n",
    "\n",
    "\n",
    "        #TODO: for log loss\n",
    "        att_weights = F.softmax(nnV)\n",
    "        logits = F.log_softmax(nnV)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return logits,att_weights\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def training_decoder(self,hn,hend,X,Xindex,Yindex,lens):\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        loss_function  = nn.NLLLoss()\n",
    "        batch_loss =0\n",
    "        LoopN =0\n",
    "        batch_size = len(lens)\n",
    "        for i in range(len(lens)): #Loop batch size\n",
    "\n",
    "            curX_index = Xindex[i]\n",
    "            curY_index = Yindex[i]\n",
    "            curL = lens[i]\n",
    "            curX = X[i]\n",
    "\n",
    "            x_index_var = Variable(torch.from_numpy(curX_index.astype(np.int64)))\n",
    "            if self.use_cuda:\n",
    "                x_index_var = x_index_var.cuda()\n",
    "\n",
    "            cur_lookup = curX[x_index_var]\n",
    "\n",
    "            curX_vectors = self.nnEm(cur_lookup)  # output: [seq,features]\n",
    "\n",
    "            curX_vectors = curX_vectors.unsqueeze(0)  # [batch, seq, features]\n",
    "\n",
    "\n",
    "\n",
    "            if self.rnn_type =='LSTM':# need h_end,c_end\n",
    "\n",
    "\n",
    "                h_end = hend[0].permute(1, 0, 2).contiguous().view(batch_size, self.num_rnn_layers,-1)\n",
    "                c_end = hend[1].permute(1, 0, 2).contiguous().view(batch_size, self.num_rnn_layers,-1)\n",
    "\n",
    "                curh0 = h_end[i].unsqueeze(0).permute(1, 0, 2)\n",
    "                curc0 = c_end[i].unsqueeze(0).permute(1, 0, 2)\n",
    "\n",
    "\n",
    "                h_pass = (curh0,curc0)\n",
    "            else:\n",
    "\n",
    "\n",
    "                h_end = hend.permute(1, 0, 2).contiguous().view(batch_size, self.num_rnn_layers,-1)\n",
    "                curh0 = h_end[i].unsqueeze(0).permute(1, 0, 2)\n",
    "                h_pass = curh0\n",
    "\n",
    "\n",
    "\n",
    "            decoder_out,_ = self.decoder_rnn(curX_vectors,h_pass)\n",
    "            decoder_out = decoder_out.squeeze(0)   #[seq,features]\n",
    "\n",
    "\n",
    "            curencoder_hn = hn[i,0:curL,:]  # hn[batch,seq,H] -->[seq,H] i is loop batch size\n",
    "\n",
    "            for j in range(len(decoder_out)):  #Loop di\n",
    "                cur_dj = decoder_out[j]\n",
    "                cur_groundy = curY_index[j]\n",
    "\n",
    "                cur_start_index = curX_index[j]\n",
    "                predict_range = list(range(cur_start_index,curL))\n",
    "\n",
    "                # TODO: make it point backward, only consider predict_range in current time step\n",
    "                # align groundtruth\n",
    "                cur_groundy_var = Variable(torch.LongTensor([int(cur_groundy) - int(cur_start_index)]))\n",
    "                if self.use_cuda:\n",
    "                    cur_groundy_var = cur_groundy_var.cuda()\n",
    "\n",
    "                curencoder_hn_back = curencoder_hn[predict_range,:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                cur_logists, cur_weights = self.pointerLayer(curencoder_hn_back,cur_dj)\n",
    "\n",
    "                batch_loss = batch_loss + loss_function(cur_logists,cur_groundy_var)\n",
    "                LoopN = LoopN +1\n",
    "\n",
    "        batch_loss = batch_loss/LoopN\n",
    "\n",
    "        return batch_loss\n",
    "\n",
    "\n",
    "    def neg_log_likelihood(self,Xin,index_decoder_x, index_decoder_y,lens):\n",
    "\n",
    "        '''\n",
    "        :param Xin:  stack_x, [allseq,wordDim]\n",
    "        :param Yin:\n",
    "        :param lens:\n",
    "        :return:\n",
    "        '''\n",
    "\n",
    "\n",
    "        encoder_hn, encoder_h_end = self.pointerEncoder(Xin,lens)\n",
    "\n",
    "        loss = self.training_decoder(encoder_hn, encoder_h_end,Xin,index_decoder_x, index_decoder_y,lens)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def test_decoder(self,hn,hend,X,Yindex,lens):\n",
    "\n",
    "        loss_function = nn.NLLLoss()\n",
    "        batch_loss = 0\n",
    "        LoopN = 0\n",
    "\n",
    "        batch_boundary =[]\n",
    "        batch_boundary_start =[]\n",
    "        batch_align_matrix =[]\n",
    "\n",
    "        batch_size = len(lens)\n",
    "\n",
    "        for i in range(len(lens)):  # Loop batch size\n",
    "\n",
    "\n",
    "\n",
    "            curL = lens[i]\n",
    "            curY_index = Yindex[i]\n",
    "            curX = X[i]\n",
    "            cur_end_boundary =curY_index[-1]\n",
    "\n",
    "            cur_boundary = []\n",
    "            cur_b_start = []\n",
    "            cur_align_matrix = []\n",
    "\n",
    "            cur_sentence_vectors = self.nnEm(curX)  # output: [seq,features]\n",
    "\n",
    "\n",
    "            if self.rnn_type =='LSTM':# need h_end,c_end\n",
    "\n",
    "\n",
    "                h_end = hend[0].permute(1, 0, 2).contiguous().view(batch_size, self.num_rnn_layers,-1)\n",
    "                c_end = hend[1].permute(1, 0, 2).contiguous().view(batch_size, self.num_rnn_layers,-1)\n",
    "\n",
    "                curh0 = h_end[i].unsqueeze(0).permute(1, 0, 2)\n",
    "                curc0 = c_end[i].unsqueeze(0).permute(1, 0, 2)\n",
    "\n",
    "                h_pass = (curh0,curc0)\n",
    "            else: # only need h_end\n",
    "\n",
    "\n",
    "                h_end = hend.permute(1, 0, 2).contiguous().view(batch_size, self.num_rnn_layers,-1)\n",
    "                curh0 = h_end[i].unsqueeze(0).permute(1, 0, 2)\n",
    "                h_pass = curh0\n",
    "\n",
    "\n",
    "\n",
    "            curencoder_hn = hn[i, 0:curL, :]  # hn[batch,seq,H] --> [seq,H]  i is loop batch size\n",
    "\n",
    "            Not_break = True\n",
    "\n",
    "            loop_in = cur_sentence_vectors[0,:].unsqueeze(0).unsqueeze(0)  #[1,1,H]\n",
    "            loop_hc = h_pass\n",
    "\n",
    "\n",
    "            loopstart =0\n",
    "\n",
    "            loop_j =0\n",
    "            while (Not_break): #if not end\n",
    "\n",
    "                loop_o, loop_hc = self.decoder_rnn(loop_in,loop_hc)\n",
    "\n",
    "\n",
    "                #TODO: make it point backward\n",
    "\n",
    "                predict_range = list(range(loopstart,curL))\n",
    "                curencoder_hn_back = curencoder_hn[predict_range,:]\n",
    "                cur_logists, cur_weights = self.pointerLayer(curencoder_hn_back, loop_o.squeeze(0).squeeze(0))\n",
    "\n",
    "                cur_align_vector = np.zeros(curL)\n",
    "                cur_align_vector[predict_range]=cur_weights.data.cpu().numpy()[0]\n",
    "                cur_align_matrix.append(cur_align_vector)\n",
    "\n",
    "                #TODO:align groundtruth\n",
    "                if loop_j > len(curY_index)-1:\n",
    "                    cur_groundy = curY_index[-1]\n",
    "                else:\n",
    "                    cur_groundy = curY_index[loop_j]\n",
    "\n",
    "\n",
    "                cur_groundy_var = Variable(torch.LongTensor([max(0,int(cur_groundy) - loopstart)]))\n",
    "                if self.use_cuda:\n",
    "                    cur_groundy_var = cur_groundy_var.cuda()\n",
    "\n",
    "                batch_loss = batch_loss + loss_function(cur_logists, cur_groundy_var)\n",
    "\n",
    "\n",
    "                #TODO: get predicted boundary\n",
    "                topv, topi = cur_logists.data.topk(1)\n",
    "\n",
    "                pred_index = topi[0][0]\n",
    "\n",
    "\n",
    "                #TODO: align pred_index to original seq\n",
    "                ori_pred_index =pred_index + loopstart\n",
    "\n",
    "\n",
    "                if cur_end_boundary == ori_pred_index:\n",
    "                    cur_boundary.append(ori_pred_index)\n",
    "                    cur_b_start.append(loopstart)\n",
    "                    Not_break = False\n",
    "                    loop_j = loop_j + 1\n",
    "                    LoopN = LoopN + 1\n",
    "                    break\n",
    "                else:\n",
    "                    cur_boundary.append(ori_pred_index)\n",
    "\n",
    "                    loop_in = cur_sentence_vectors[ori_pred_index+1,:].unsqueeze(0).unsqueeze(0)\n",
    "                    cur_b_start.append(loopstart)\n",
    "\n",
    "                    loopstart = ori_pred_index+1  # start =  pred_end + 1\n",
    "\n",
    "                    loop_j = loop_j + 1\n",
    "                    LoopN = LoopN + 1\n",
    "\n",
    "\n",
    "            #For each instance in batch\n",
    "            batch_boundary.append(cur_boundary)\n",
    "            batch_boundary_start.append(cur_b_start)\n",
    "            batch_align_matrix.append(cur_align_matrix)\n",
    "\n",
    "        batch_loss = batch_loss / LoopN\n",
    "\n",
    "        batch_boundary=np.array(batch_boundary)\n",
    "        batch_boundary_start = np.array(batch_boundary_start)\n",
    "        batch_align_matrix = np.array(batch_align_matrix)\n",
    "\n",
    "        return batch_loss,batch_boundary,batch_boundary_start,batch_align_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self,Xin,index_decoder_y,lens):\n",
    "\n",
    "        batch_size = index_decoder_y.shape[0]\n",
    "\n",
    "        encoder_hn, encoder_h_end = self.pointerEncoder(Xin, lens)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        batch_loss, batch_boundary, batch_boundary_start, batch_align_matrix = self.test_decoder(encoder_hn,encoder_h_end,Xin,index_decoder_y,lens)\n",
    "\n",
    "        return  batch_loss,batch_boundary,batch_boundary_start,batch_align_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
